{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0f5aca27",
   "metadata": {},
   "source": [
    "# Training an OAE to reduce the dimension of the input by nonlinear mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fb24974f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing libraries and methods\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from feature_extraction.oae_fit_transform import DimensionalityReductionOAE\n",
    "import os\n",
    "import random\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ca576ec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing data\n",
    "# TEP: we use Stream9E (purge composition measurement)\n",
    "df = pd.read_csv(\"/Users/dcac/Desktop/PhD/Data/TEP/Extended/tep_extended_compositions_1min.csv\")\n",
    "cols_to_drop = ['Stream9A', 'Stream9B', 'Stream9C', 'Stream9D', 'Stream9E', 'Stream9F', 'Stream9G', 'Stream9H',\n",
    "                'Stream11D', 'Stream11E', 'Stream11F', 'Stream11G', 'Stream11H']\n",
    "cols_to_drop_updated = [col for col in cols_to_drop if col != 'Stream9E']\n",
    "df = df.drop(cols_to_drop_updated, axis=1)\n",
    "df.rename(columns={'Stream9E': 'y'}, inplace=True)\n",
    "\n",
    "# Taking last run to fit OAE\n",
    "training_set = df[df[\"RUN\"] == 59].drop(\"RUN\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4893af13",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[   1/1000] train_loss: 9497.888801 valid_loss: 6086.214993\n",
      "Validation loss decreased (inf --> 6086.214993).  Saving model ...\n",
      "[   2/1000] train_loss: 7491.568239 valid_loss: 6818.102752\n",
      "EarlyStopping counter: 1 out of 10\n",
      "[   3/1000] train_loss: 6224.566536 valid_loss: 5529.828531\n",
      "Validation loss decreased (6086.214993 --> 5529.828531).  Saving model ...\n",
      "[   4/1000] train_loss: 5198.650961 valid_loss: 4532.636891\n",
      "Validation loss decreased (5529.828531 --> 4532.636891).  Saving model ...\n",
      "[   5/1000] train_loss: 4362.927936 valid_loss: 3822.291748\n",
      "Validation loss decreased (4532.636891 --> 3822.291748).  Saving model ...\n",
      "[   6/1000] train_loss: 3672.914403 valid_loss: 3285.313703\n",
      "Validation loss decreased (3822.291748 --> 3285.313703).  Saving model ...\n",
      "[   7/1000] train_loss: 3105.740918 valid_loss: 2677.689485\n",
      "Validation loss decreased (3285.313703 --> 2677.689485).  Saving model ...\n",
      "[   8/1000] train_loss: 2642.033635 valid_loss: 2317.251463\n",
      "Validation loss decreased (2677.689485 --> 2317.251463).  Saving model ...\n",
      "[   9/1000] train_loss: 2255.633725 valid_loss: 2024.178954\n",
      "Validation loss decreased (2317.251463 --> 2024.178954).  Saving model ...\n",
      "[  10/1000] train_loss: 1934.481178 valid_loss: 1771.720713\n",
      "Validation loss decreased (2024.178954 --> 1771.720713).  Saving model ...\n",
      "[  11/1000] train_loss: 1666.289546 valid_loss: 1528.518829\n",
      "Validation loss decreased (1771.720713 --> 1528.518829).  Saving model ...\n",
      "[  12/1000] train_loss: 1440.348216 valid_loss: 1308.846675\n",
      "Validation loss decreased (1528.518829 --> 1308.846675).  Saving model ...\n",
      "[  13/1000] train_loss: 1250.139712 valid_loss: 1104.548468\n",
      "Validation loss decreased (1308.846675 --> 1104.548468).  Saving model ...\n",
      "[  14/1000] train_loss: 1089.011418 valid_loss: 956.628542\n",
      "Validation loss decreased (1104.548468 --> 956.628542).  Saving model ...\n",
      "[  15/1000] train_loss: 952.091735 valid_loss: 853.534325\n",
      "Validation loss decreased (956.628542 --> 853.534325).  Saving model ...\n",
      "[  16/1000] train_loss: 835.344673 valid_loss: 739.201493\n",
      "Validation loss decreased (853.534325 --> 739.201493).  Saving model ...\n",
      "[  17/1000] train_loss: 735.181857 valid_loss: 684.047252\n",
      "Validation loss decreased (739.201493 --> 684.047252).  Saving model ...\n",
      "[  18/1000] train_loss: 648.962928 valid_loss: 579.877485\n",
      "Validation loss decreased (684.047252 --> 579.877485).  Saving model ...\n",
      "[  19/1000] train_loss: 574.533023 valid_loss: 519.920765\n",
      "Validation loss decreased (579.877485 --> 519.920765).  Saving model ...\n",
      "[  20/1000] train_loss: 510.158798 valid_loss: 449.436048\n",
      "Validation loss decreased (519.920765 --> 449.436048).  Saving model ...\n",
      "[  21/1000] train_loss: 453.921060 valid_loss: 398.208701\n",
      "Validation loss decreased (449.436048 --> 398.208701).  Saving model ...\n",
      "[  22/1000] train_loss: 405.302441 valid_loss: 376.497387\n",
      "Validation loss decreased (398.208701 --> 376.497387).  Saving model ...\n",
      "[  23/1000] train_loss: 362.533119 valid_loss: 329.529294\n",
      "Validation loss decreased (376.497387 --> 329.529294).  Saving model ...\n",
      "[  24/1000] train_loss: 325.099323 valid_loss: 297.908616\n",
      "Validation loss decreased (329.529294 --> 297.908616).  Saving model ...\n",
      "[  25/1000] train_loss: 292.081641 valid_loss: 259.705298\n",
      "Validation loss decreased (297.908616 --> 259.705298).  Saving model ...\n",
      "[  26/1000] train_loss: 263.084674 valid_loss: 234.823385\n",
      "Validation loss decreased (259.705298 --> 234.823385).  Saving model ...\n",
      "[  27/1000] train_loss: 237.398104 valid_loss: 213.494320\n",
      "Validation loss decreased (234.823385 --> 213.494320).  Saving model ...\n",
      "[  28/1000] train_loss: 214.616400 valid_loss: 195.416052\n",
      "Validation loss decreased (213.494320 --> 195.416052).  Saving model ...\n",
      "[  29/1000] train_loss: 194.401892 valid_loss: 177.217164\n",
      "Validation loss decreased (195.416052 --> 177.217164).  Saving model ...\n",
      "[  30/1000] train_loss: 176.342442 valid_loss: 160.466254\n",
      "Validation loss decreased (177.217164 --> 160.466254).  Saving model ...\n",
      "[  31/1000] train_loss: 160.366830 valid_loss: 145.704283\n",
      "Validation loss decreased (160.466254 --> 145.704283).  Saving model ...\n",
      "[  32/1000] train_loss: 145.963743 valid_loss: 133.592583\n",
      "Validation loss decreased (145.704283 --> 133.592583).  Saving model ...\n",
      "[  33/1000] train_loss: 133.074628 valid_loss: 122.468082\n",
      "Validation loss decreased (133.592583 --> 122.468082).  Saving model ...\n",
      "[  34/1000] train_loss: 121.506456 valid_loss: 111.129670\n",
      "Validation loss decreased (122.468082 --> 111.129670).  Saving model ...\n",
      "[  35/1000] train_loss: 111.146140 valid_loss: 104.957930\n",
      "Validation loss decreased (111.129670 --> 104.957930).  Saving model ...\n",
      "[  36/1000] train_loss: 101.805007 valid_loss: 92.835079\n",
      "Validation loss decreased (104.957930 --> 92.835079).  Saving model ...\n",
      "[  37/1000] train_loss: 93.346936 valid_loss: 82.449605\n",
      "Validation loss decreased (92.835079 --> 82.449605).  Saving model ...\n",
      "[  38/1000] train_loss: 85.677406 valid_loss: 76.811338\n",
      "Validation loss decreased (82.449605 --> 76.811338).  Saving model ...\n",
      "[  39/1000] train_loss: 78.766275 valid_loss: 69.762354\n",
      "Validation loss decreased (76.811338 --> 69.762354).  Saving model ...\n",
      "[  40/1000] train_loss: 72.465596 valid_loss: 65.238499\n",
      "Validation loss decreased (69.762354 --> 65.238499).  Saving model ...\n",
      "[  41/1000] train_loss: 66.776344 valid_loss: 61.673786\n",
      "Validation loss decreased (65.238499 --> 61.673786).  Saving model ...\n",
      "[  42/1000] train_loss: 61.588755 valid_loss: 55.401600\n",
      "Validation loss decreased (61.673786 --> 55.401600).  Saving model ...\n",
      "[  43/1000] train_loss: 56.857150 valid_loss: 51.007349\n",
      "Validation loss decreased (55.401600 --> 51.007349).  Saving model ...\n",
      "[  44/1000] train_loss: 52.568775 valid_loss: 47.589551\n",
      "Validation loss decreased (51.007349 --> 47.589551).  Saving model ...\n",
      "[  45/1000] train_loss: 48.627760 valid_loss: 43.908415\n",
      "Validation loss decreased (47.589551 --> 43.908415).  Saving model ...\n",
      "[  46/1000] train_loss: 45.033129 valid_loss: 40.652465\n",
      "Validation loss decreased (43.908415 --> 40.652465).  Saving model ...\n",
      "[  47/1000] train_loss: 41.742864 valid_loss: 38.472805\n",
      "Validation loss decreased (40.652465 --> 38.472805).  Saving model ...\n",
      "[  48/1000] train_loss: 38.740070 valid_loss: 34.699491\n",
      "Validation loss decreased (38.472805 --> 34.699491).  Saving model ...\n",
      "[  49/1000] train_loss: 35.952772 valid_loss: 33.331781\n",
      "Validation loss decreased (34.699491 --> 33.331781).  Saving model ...\n",
      "[  50/1000] train_loss: 33.412665 valid_loss: 30.080794\n",
      "Validation loss decreased (33.331781 --> 30.080794).  Saving model ...\n",
      "[  51/1000] train_loss: 31.079904 valid_loss: 29.432683\n",
      "Validation loss decreased (30.080794 --> 29.432683).  Saving model ...\n",
      "[  52/1000] train_loss: 28.932713 valid_loss: 26.881153\n",
      "Validation loss decreased (29.432683 --> 26.881153).  Saving model ...\n",
      "[  53/1000] train_loss: 26.954180 valid_loss: 25.916772\n",
      "Validation loss decreased (26.881153 --> 25.916772).  Saving model ...\n",
      "[  54/1000] train_loss: 25.125906 valid_loss: 22.441633\n",
      "Validation loss decreased (25.916772 --> 22.441633).  Saving model ...\n",
      "[  55/1000] train_loss: 23.444757 valid_loss: 20.922453\n",
      "Validation loss decreased (22.441633 --> 20.922453).  Saving model ...\n",
      "[  56/1000] train_loss: 21.890682 valid_loss: 19.410702\n",
      "Validation loss decreased (20.922453 --> 19.410702).  Saving model ...\n",
      "[  57/1000] train_loss: 20.448533 valid_loss: 18.683248\n",
      "Validation loss decreased (19.410702 --> 18.683248).  Saving model ...\n",
      "[  58/1000] train_loss: 19.114600 valid_loss: 17.479004\n",
      "Validation loss decreased (18.683248 --> 17.479004).  Saving model ...\n",
      "[  59/1000] train_loss: 17.881114 valid_loss: 16.746330\n",
      "Validation loss decreased (17.479004 --> 16.746330).  Saving model ...\n",
      "[  60/1000] train_loss: 16.742815 valid_loss: 15.706324\n",
      "Validation loss decreased (16.746330 --> 15.706324).  Saving model ...\n",
      "[  61/1000] train_loss: 15.679988 valid_loss: 14.675566\n",
      "Validation loss decreased (15.706324 --> 14.675566).  Saving model ...\n",
      "[  62/1000] train_loss: 14.701839 valid_loss: 14.011452\n",
      "Validation loss decreased (14.675566 --> 14.011452).  Saving model ...\n",
      "[  63/1000] train_loss: 13.783772 valid_loss: 12.514083\n",
      "Validation loss decreased (14.011452 --> 12.514083).  Saving model ...\n",
      "[  64/1000] train_loss: 12.936884 valid_loss: 11.855292\n",
      "Validation loss decreased (12.514083 --> 11.855292).  Saving model ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  65/1000] train_loss: 12.149395 valid_loss: 10.982046\n",
      "Validation loss decreased (11.855292 --> 10.982046).  Saving model ...\n",
      "[  66/1000] train_loss: 11.415560 valid_loss: 10.224300\n",
      "Validation loss decreased (10.982046 --> 10.224300).  Saving model ...\n",
      "[  67/1000] train_loss: 10.731255 valid_loss: 9.704868\n",
      "Validation loss decreased (10.224300 --> 9.704868).  Saving model ...\n",
      "[  68/1000] train_loss: 10.096114 valid_loss: 9.436969\n",
      "Validation loss decreased (9.704868 --> 9.436969).  Saving model ...\n",
      "[  69/1000] train_loss: 9.501892 valid_loss: 8.812246\n",
      "Validation loss decreased (9.436969 --> 8.812246).  Saving model ...\n",
      "[  70/1000] train_loss: 8.950186 valid_loss: 8.423225\n",
      "Validation loss decreased (8.812246 --> 8.423225).  Saving model ...\n",
      "[  71/1000] train_loss: 8.431250 valid_loss: 7.584281\n",
      "Validation loss decreased (8.423225 --> 7.584281).  Saving model ...\n",
      "[  72/1000] train_loss: 7.949983 valid_loss: 7.433499\n",
      "Validation loss decreased (7.584281 --> 7.433499).  Saving model ...\n",
      "[  73/1000] train_loss: 7.501451 valid_loss: 7.107534\n",
      "Validation loss decreased (7.433499 --> 7.107534).  Saving model ...\n",
      "[  74/1000] train_loss: 7.079230 valid_loss: 6.780850\n",
      "Validation loss decreased (7.107534 --> 6.780850).  Saving model ...\n",
      "[  75/1000] train_loss: 6.686204 valid_loss: 6.148940\n",
      "Validation loss decreased (6.780850 --> 6.148940).  Saving model ...\n",
      "[  76/1000] train_loss: 6.318222 valid_loss: 5.914322\n",
      "Validation loss decreased (6.148940 --> 5.914322).  Saving model ...\n",
      "[  77/1000] train_loss: 5.972416 valid_loss: 5.762992\n",
      "Validation loss decreased (5.914322 --> 5.762992).  Saving model ...\n",
      "[  78/1000] train_loss: 5.651034 valid_loss: 5.322470\n",
      "Validation loss decreased (5.762992 --> 5.322470).  Saving model ...\n",
      "[  79/1000] train_loss: 5.350676 valid_loss: 5.122857\n",
      "Validation loss decreased (5.322470 --> 5.122857).  Saving model ...\n",
      "[  80/1000] train_loss: 5.064656 valid_loss: 4.615076\n",
      "Validation loss decreased (5.122857 --> 4.615076).  Saving model ...\n",
      "[  81/1000] train_loss: 4.801109 valid_loss: 4.395890\n",
      "Validation loss decreased (4.615076 --> 4.395890).  Saving model ...\n",
      "[  82/1000] train_loss: 4.551152 valid_loss: 4.285908\n",
      "Validation loss decreased (4.395890 --> 4.285908).  Saving model ...\n",
      "[  83/1000] train_loss: 4.317630 valid_loss: 4.124563\n",
      "Validation loss decreased (4.285908 --> 4.124563).  Saving model ...\n",
      "[  84/1000] train_loss: 4.100976 valid_loss: 3.832508\n",
      "Validation loss decreased (4.124563 --> 3.832508).  Saving model ...\n",
      "[  85/1000] train_loss: 3.893887 valid_loss: 3.608347\n",
      "Validation loss decreased (3.832508 --> 3.608347).  Saving model ...\n",
      "[  86/1000] train_loss: 3.700513 valid_loss: 3.562824\n",
      "Validation loss decreased (3.608347 --> 3.562824).  Saving model ...\n",
      "[  87/1000] train_loss: 3.517668 valid_loss: 3.263267\n",
      "Validation loss decreased (3.562824 --> 3.263267).  Saving model ...\n",
      "[  88/1000] train_loss: 3.345970 valid_loss: 3.057321\n",
      "Validation loss decreased (3.263267 --> 3.057321).  Saving model ...\n",
      "[  89/1000] train_loss: 3.185499 valid_loss: 3.085612\n",
      "EarlyStopping counter: 1 out of 10\n",
      "[  90/1000] train_loss: 3.035764 valid_loss: 2.850005\n",
      "Validation loss decreased (3.057321 --> 2.850005).  Saving model ...\n",
      "[  91/1000] train_loss: 2.894545 valid_loss: 2.730226\n",
      "Validation loss decreased (2.850005 --> 2.730226).  Saving model ...\n",
      "[  92/1000] train_loss: 2.760259 valid_loss: 2.577238\n",
      "Validation loss decreased (2.730226 --> 2.577238).  Saving model ...\n",
      "[  93/1000] train_loss: 2.634972 valid_loss: 2.527865\n",
      "Validation loss decreased (2.577238 --> 2.527865).  Saving model ...\n",
      "[  94/1000] train_loss: 2.515175 valid_loss: 2.446558\n",
      "Validation loss decreased (2.527865 --> 2.446558).  Saving model ...\n",
      "[  95/1000] train_loss: 2.403423 valid_loss: 2.210997\n",
      "Validation loss decreased (2.446558 --> 2.210997).  Saving model ...\n",
      "[  96/1000] train_loss: 2.297948 valid_loss: 2.151367\n",
      "Validation loss decreased (2.210997 --> 2.151367).  Saving model ...\n",
      "[  97/1000] train_loss: 2.199712 valid_loss: 2.111931\n",
      "Validation loss decreased (2.151367 --> 2.111931).  Saving model ...\n",
      "[  98/1000] train_loss: 2.106034 valid_loss: 1.964487\n",
      "Validation loss decreased (2.111931 --> 1.964487).  Saving model ...\n",
      "[  99/1000] train_loss: 2.017010 valid_loss: 1.911036\n",
      "Validation loss decreased (1.964487 --> 1.911036).  Saving model ...\n",
      "[ 100/1000] train_loss: 1.935428 valid_loss: 1.828031\n",
      "Validation loss decreased (1.911036 --> 1.828031).  Saving model ...\n",
      "[ 101/1000] train_loss: 1.855722 valid_loss: 1.743597\n",
      "Validation loss decreased (1.828031 --> 1.743597).  Saving model ...\n",
      "[ 102/1000] train_loss: 1.782778 valid_loss: 1.670882\n",
      "Validation loss decreased (1.743597 --> 1.670882).  Saving model ...\n",
      "[ 103/1000] train_loss: 1.711887 valid_loss: 1.617847\n",
      "Validation loss decreased (1.670882 --> 1.617847).  Saving model ...\n",
      "[ 104/1000] train_loss: 1.646819 valid_loss: 1.568136\n",
      "Validation loss decreased (1.617847 --> 1.568136).  Saving model ...\n",
      "[ 105/1000] train_loss: 1.583947 valid_loss: 1.487002\n",
      "Validation loss decreased (1.568136 --> 1.487002).  Saving model ...\n",
      "[ 106/1000] train_loss: 1.524318 valid_loss: 1.477578\n",
      "Validation loss decreased (1.487002 --> 1.477578).  Saving model ...\n",
      "[ 107/1000] train_loss: 1.469818 valid_loss: 1.430492\n",
      "Validation loss decreased (1.477578 --> 1.430492).  Saving model ...\n",
      "[ 108/1000] train_loss: 1.417573 valid_loss: 1.365523\n",
      "Validation loss decreased (1.430492 --> 1.365523).  Saving model ...\n",
      "[ 109/1000] train_loss: 1.367354 valid_loss: 1.307815\n",
      "Validation loss decreased (1.365523 --> 1.307815).  Saving model ...\n",
      "[ 110/1000] train_loss: 1.319796 valid_loss: 1.279265\n",
      "Validation loss decreased (1.307815 --> 1.279265).  Saving model ...\n",
      "[ 111/1000] train_loss: 1.274917 valid_loss: 1.243462\n",
      "Validation loss decreased (1.279265 --> 1.243462).  Saving model ...\n",
      "[ 112/1000] train_loss: 1.232178 valid_loss: 1.217192\n",
      "Validation loss decreased (1.243462 --> 1.217192).  Saving model ...\n",
      "[ 113/1000] train_loss: 1.193156 valid_loss: 1.161993\n",
      "Validation loss decreased (1.217192 --> 1.161993).  Saving model ...\n",
      "[ 114/1000] train_loss: 1.155900 valid_loss: 1.134073\n",
      "Validation loss decreased (1.161993 --> 1.134073).  Saving model ...\n",
      "[ 115/1000] train_loss: 1.120381 valid_loss: 1.107221\n",
      "Validation loss decreased (1.134073 --> 1.107221).  Saving model ...\n",
      "[ 116/1000] train_loss: 1.086099 valid_loss: 1.071680\n",
      "Validation loss decreased (1.107221 --> 1.071680).  Saving model ...\n",
      "[ 117/1000] train_loss: 1.053399 valid_loss: 1.029840\n",
      "Validation loss decreased (1.071680 --> 1.029840).  Saving model ...\n",
      "[ 118/1000] train_loss: 1.023210 valid_loss: 1.016260\n",
      "Validation loss decreased (1.029840 --> 1.016260).  Saving model ...\n",
      "[ 119/1000] train_loss: 0.994066 valid_loss: 1.001235\n",
      "Validation loss decreased (1.016260 --> 1.001235).  Saving model ...\n",
      "[ 120/1000] train_loss: 0.967530 valid_loss: 0.943676\n",
      "Validation loss decreased (1.001235 --> 0.943676).  Saving model ...\n",
      "[ 121/1000] train_loss: 0.941706 valid_loss: 0.930184\n",
      "Validation loss decreased (0.943676 --> 0.930184).  Saving model ...\n",
      "[ 122/1000] train_loss: 0.916382 valid_loss: 0.892771\n",
      "Validation loss decreased (0.930184 --> 0.892771).  Saving model ...\n",
      "[ 123/1000] train_loss: 0.893666 valid_loss: 0.884336\n",
      "Validation loss decreased (0.892771 --> 0.884336).  Saving model ...\n",
      "[ 124/1000] train_loss: 0.871675 valid_loss: 0.852585\n",
      "Validation loss decreased (0.884336 --> 0.852585).  Saving model ...\n",
      "[ 125/1000] train_loss: 0.849892 valid_loss: 0.843541\n",
      "Validation loss decreased (0.852585 --> 0.843541).  Saving model ...\n",
      "[ 126/1000] train_loss: 0.830029 valid_loss: 0.820697\n",
      "Validation loss decreased (0.843541 --> 0.820697).  Saving model ...\n",
      "[ 127/1000] train_loss: 0.812135 valid_loss: 0.803998\n",
      "Validation loss decreased (0.820697 --> 0.803998).  Saving model ...\n",
      "[ 128/1000] train_loss: 0.793164 valid_loss: 0.785624\n",
      "Validation loss decreased (0.803998 --> 0.785624).  Saving model ...\n",
      "[ 129/1000] train_loss: 0.775870 valid_loss: 0.768673\n",
      "Validation loss decreased (0.785624 --> 0.768673).  Saving model ...\n",
      "[ 130/1000] train_loss: 0.760061 valid_loss: 0.760013\n",
      "Validation loss decreased (0.768673 --> 0.760013).  Saving model ...\n",
      "[ 131/1000] train_loss: 0.745380 valid_loss: 0.739074\n",
      "Validation loss decreased (0.760013 --> 0.739074).  Saving model ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 132/1000] train_loss: 0.728832 valid_loss: 0.726920\n",
      "Validation loss decreased (0.739074 --> 0.726920).  Saving model ...\n",
      "[ 133/1000] train_loss: 0.715387 valid_loss: 0.720081\n",
      "Validation loss decreased (0.726920 --> 0.720081).  Saving model ...\n",
      "[ 134/1000] train_loss: 0.702665 valid_loss: 0.705148\n",
      "Validation loss decreased (0.720081 --> 0.705148).  Saving model ...\n",
      "[ 135/1000] train_loss: 0.690225 valid_loss: 0.682236\n",
      "Validation loss decreased (0.705148 --> 0.682236).  Saving model ...\n",
      "[ 136/1000] train_loss: 0.678697 valid_loss: 0.674590\n",
      "Validation loss decreased (0.682236 --> 0.674590).  Saving model ...\n",
      "[ 137/1000] train_loss: 0.667217 valid_loss: 0.669952\n",
      "Validation loss decreased (0.674590 --> 0.669952).  Saving model ...\n",
      "[ 138/1000] train_loss: 0.656083 valid_loss: 0.659882\n",
      "Validation loss decreased (0.669952 --> 0.659882).  Saving model ...\n",
      "[ 139/1000] train_loss: 0.644495 valid_loss: 0.646067\n",
      "Validation loss decreased (0.659882 --> 0.646067).  Saving model ...\n",
      "[ 140/1000] train_loss: 0.634871 valid_loss: 0.631370\n",
      "Validation loss decreased (0.646067 --> 0.631370).  Saving model ...\n",
      "[ 141/1000] train_loss: 0.625090 valid_loss: 0.627375\n",
      "Validation loss decreased (0.631370 --> 0.627375).  Saving model ...\n",
      "[ 142/1000] train_loss: 0.615857 valid_loss: 0.621534\n",
      "Validation loss decreased (0.627375 --> 0.621534).  Saving model ...\n",
      "[ 143/1000] train_loss: 0.607476 valid_loss: 0.615064\n",
      "Validation loss decreased (0.621534 --> 0.615064).  Saving model ...\n",
      "[ 144/1000] train_loss: 0.598940 valid_loss: 0.598810\n",
      "Validation loss decreased (0.615064 --> 0.598810).  Saving model ...\n",
      "[ 145/1000] train_loss: 0.591963 valid_loss: 0.591914\n",
      "Validation loss decreased (0.598810 --> 0.591914).  Saving model ...\n",
      "[ 146/1000] train_loss: 0.584132 valid_loss: 0.595832\n",
      "EarlyStopping counter: 1 out of 10\n",
      "[ 147/1000] train_loss: 0.577428 valid_loss: 0.582814\n",
      "Validation loss decreased (0.591914 --> 0.582814).  Saving model ...\n",
      "[ 148/1000] train_loss: 0.568806 valid_loss: 0.572242\n",
      "Validation loss decreased (0.582814 --> 0.572242).  Saving model ...\n",
      "[ 149/1000] train_loss: 0.563486 valid_loss: 0.568455\n",
      "Validation loss decreased (0.572242 --> 0.568455).  Saving model ...\n",
      "[ 150/1000] train_loss: 0.555752 valid_loss: 0.574128\n",
      "EarlyStopping counter: 1 out of 10\n",
      "[ 151/1000] train_loss: 0.549524 valid_loss: 0.558636\n",
      "Validation loss decreased (0.568455 --> 0.558636).  Saving model ...\n",
      "[ 152/1000] train_loss: 0.543745 valid_loss: 0.561053\n",
      "EarlyStopping counter: 1 out of 10\n",
      "[ 153/1000] train_loss: 0.538780 valid_loss: 0.553844\n",
      "Validation loss decreased (0.558636 --> 0.553844).  Saving model ...\n",
      "[ 154/1000] train_loss: 0.532980 valid_loss: 0.542676\n",
      "Validation loss decreased (0.553844 --> 0.542676).  Saving model ...\n",
      "[ 155/1000] train_loss: 0.526853 valid_loss: 0.540751\n",
      "Validation loss decreased (0.542676 --> 0.540751).  Saving model ...\n",
      "[ 156/1000] train_loss: 0.521683 valid_loss: 0.532144\n",
      "Validation loss decreased (0.540751 --> 0.532144).  Saving model ...\n",
      "[ 157/1000] train_loss: 0.516539 valid_loss: 0.524639\n",
      "Validation loss decreased (0.532144 --> 0.524639).  Saving model ...\n",
      "[ 158/1000] train_loss: 0.511656 valid_loss: 0.525404\n",
      "EarlyStopping counter: 1 out of 10\n",
      "[ 159/1000] train_loss: 0.507081 valid_loss: 0.519478\n",
      "Validation loss decreased (0.524639 --> 0.519478).  Saving model ...\n",
      "[ 160/1000] train_loss: 0.503279 valid_loss: 0.511057\n",
      "Validation loss decreased (0.519478 --> 0.511057).  Saving model ...\n",
      "[ 161/1000] train_loss: 0.499541 valid_loss: 0.511018\n",
      "Validation loss decreased (0.511057 --> 0.511018).  Saving model ...\n",
      "[ 162/1000] train_loss: 0.494733 valid_loss: 0.508143\n",
      "Validation loss decreased (0.511018 --> 0.508143).  Saving model ...\n",
      "[ 163/1000] train_loss: 0.490059 valid_loss: 0.507116\n",
      "Validation loss decreased (0.508143 --> 0.507116).  Saving model ...\n",
      "[ 164/1000] train_loss: 0.485983 valid_loss: 0.508210\n",
      "EarlyStopping counter: 1 out of 10\n",
      "[ 165/1000] train_loss: 0.481838 valid_loss: 0.497244\n",
      "Validation loss decreased (0.507116 --> 0.497244).  Saving model ...\n",
      "[ 166/1000] train_loss: 0.479607 valid_loss: 0.490902\n",
      "Validation loss decreased (0.497244 --> 0.490902).  Saving model ...\n",
      "[ 167/1000] train_loss: 0.474047 valid_loss: 0.485434\n",
      "Validation loss decreased (0.490902 --> 0.485434).  Saving model ...\n",
      "[ 168/1000] train_loss: 0.472156 valid_loss: 0.478716\n",
      "Validation loss decreased (0.485434 --> 0.478716).  Saving model ...\n",
      "[ 169/1000] train_loss: 0.468647 valid_loss: 0.480587\n",
      "EarlyStopping counter: 1 out of 10\n",
      "[ 170/1000] train_loss: 0.464229 valid_loss: 0.479499\n",
      "EarlyStopping counter: 2 out of 10\n",
      "[ 171/1000] train_loss: 0.461282 valid_loss: 0.478665\n",
      "Validation loss decreased (0.478716 --> 0.478665).  Saving model ...\n",
      "[ 172/1000] train_loss: 0.458299 valid_loss: 0.469759\n",
      "Validation loss decreased (0.478665 --> 0.469759).  Saving model ...\n",
      "[ 173/1000] train_loss: 0.454836 valid_loss: 0.470999\n",
      "EarlyStopping counter: 1 out of 10\n",
      "[ 174/1000] train_loss: 0.452355 valid_loss: 0.468179\n",
      "Validation loss decreased (0.469759 --> 0.468179).  Saving model ...\n",
      "[ 175/1000] train_loss: 0.448357 valid_loss: 0.465337\n",
      "Validation loss decreased (0.468179 --> 0.465337).  Saving model ...\n",
      "[ 176/1000] train_loss: 0.445483 valid_loss: 0.452903\n",
      "Validation loss decreased (0.465337 --> 0.452903).  Saving model ...\n",
      "[ 177/1000] train_loss: 0.442336 valid_loss: 0.458876\n",
      "EarlyStopping counter: 1 out of 10\n",
      "[ 178/1000] train_loss: 0.439764 valid_loss: 0.449565\n",
      "Validation loss decreased (0.452903 --> 0.449565).  Saving model ...\n",
      "[ 179/1000] train_loss: 0.436435 valid_loss: 0.452183\n",
      "EarlyStopping counter: 1 out of 10\n",
      "[ 180/1000] train_loss: 0.434139 valid_loss: 0.447826\n",
      "Validation loss decreased (0.449565 --> 0.447826).  Saving model ...\n",
      "[ 181/1000] train_loss: 0.431574 valid_loss: 0.448612\n",
      "EarlyStopping counter: 1 out of 10\n",
      "[ 182/1000] train_loss: 0.428255 valid_loss: 0.447881\n",
      "EarlyStopping counter: 2 out of 10\n",
      "[ 183/1000] train_loss: 0.424702 valid_loss: 0.437141\n",
      "Validation loss decreased (0.447826 --> 0.437141).  Saving model ...\n",
      "[ 184/1000] train_loss: 0.422148 valid_loss: 0.433731\n",
      "Validation loss decreased (0.437141 --> 0.433731).  Saving model ...\n",
      "[ 185/1000] train_loss: 0.419592 valid_loss: 0.432552\n",
      "Validation loss decreased (0.433731 --> 0.432552).  Saving model ...\n",
      "[ 186/1000] train_loss: 0.416982 valid_loss: 0.437297\n",
      "EarlyStopping counter: 1 out of 10\n",
      "[ 187/1000] train_loss: 0.413452 valid_loss: 0.442873\n",
      "EarlyStopping counter: 2 out of 10\n",
      "[ 188/1000] train_loss: 0.411035 valid_loss: 0.424307\n",
      "Validation loss decreased (0.432552 --> 0.424307).  Saving model ...\n",
      "[ 189/1000] train_loss: 0.408036 valid_loss: 0.415162\n",
      "Validation loss decreased (0.424307 --> 0.415162).  Saving model ...\n",
      "[ 190/1000] train_loss: 0.405664 valid_loss: 0.422479\n",
      "EarlyStopping counter: 1 out of 10\n",
      "[ 191/1000] train_loss: 0.403979 valid_loss: 0.421093\n",
      "EarlyStopping counter: 2 out of 10\n",
      "[ 192/1000] train_loss: 0.400962 valid_loss: 0.412472\n",
      "Validation loss decreased (0.415162 --> 0.412472).  Saving model ...\n",
      "[ 193/1000] train_loss: 0.398535 valid_loss: 0.413637\n",
      "EarlyStopping counter: 1 out of 10\n",
      "[ 194/1000] train_loss: 0.395650 valid_loss: 0.406941\n",
      "Validation loss decreased (0.412472 --> 0.406941).  Saving model ...\n",
      "[ 195/1000] train_loss: 0.392606 valid_loss: 0.414003\n",
      "EarlyStopping counter: 1 out of 10\n",
      "[ 196/1000] train_loss: 0.389919 valid_loss: 0.403305\n",
      "Validation loss decreased (0.406941 --> 0.403305).  Saving model ...\n",
      "[ 197/1000] train_loss: 0.388418 valid_loss: 0.400040\n",
      "Validation loss decreased (0.403305 --> 0.400040).  Saving model ...\n",
      "[ 198/1000] train_loss: 0.385904 valid_loss: 0.405466\n",
      "EarlyStopping counter: 1 out of 10\n",
      "[ 199/1000] train_loss: 0.383372 valid_loss: 0.402432\n",
      "EarlyStopping counter: 2 out of 10\n",
      "[ 200/1000] train_loss: 0.380814 valid_loss: 0.399834\n",
      "Validation loss decreased (0.400040 --> 0.399834).  Saving model ...\n",
      "[ 201/1000] train_loss: 0.378157 valid_loss: 0.393202\n",
      "Validation loss decreased (0.399834 --> 0.393202).  Saving model ...\n",
      "[ 202/1000] train_loss: 0.375262 valid_loss: 0.393764\n",
      "EarlyStopping counter: 1 out of 10\n",
      "[ 203/1000] train_loss: 0.372778 valid_loss: 0.389099\n",
      "Validation loss decreased (0.393202 --> 0.389099).  Saving model ...\n",
      "[ 204/1000] train_loss: 0.369576 valid_loss: 0.389197\n",
      "EarlyStopping counter: 1 out of 10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 205/1000] train_loss: 0.368057 valid_loss: 0.384729\n",
      "Validation loss decreased (0.389099 --> 0.384729).  Saving model ...\n",
      "[ 206/1000] train_loss: 0.365489 valid_loss: 0.376603\n",
      "Validation loss decreased (0.384729 --> 0.376603).  Saving model ...\n",
      "[ 207/1000] train_loss: 0.362866 valid_loss: 0.378961\n",
      "EarlyStopping counter: 1 out of 10\n",
      "[ 208/1000] train_loss: 0.360094 valid_loss: 0.378493\n",
      "EarlyStopping counter: 2 out of 10\n",
      "[ 209/1000] train_loss: 0.358388 valid_loss: 0.368911\n",
      "Validation loss decreased (0.376603 --> 0.368911).  Saving model ...\n",
      "[ 210/1000] train_loss: 0.355715 valid_loss: 0.371031\n",
      "EarlyStopping counter: 1 out of 10\n",
      "[ 211/1000] train_loss: 0.352869 valid_loss: 0.359428\n",
      "Validation loss decreased (0.368911 --> 0.359428).  Saving model ...\n",
      "[ 212/1000] train_loss: 0.350672 valid_loss: 0.371253\n",
      "EarlyStopping counter: 1 out of 10\n",
      "[ 213/1000] train_loss: 0.348088 valid_loss: 0.357840\n",
      "Validation loss decreased (0.359428 --> 0.357840).  Saving model ...\n",
      "[ 214/1000] train_loss: 0.345114 valid_loss: 0.356956\n",
      "Validation loss decreased (0.357840 --> 0.356956).  Saving model ...\n",
      "[ 215/1000] train_loss: 0.342823 valid_loss: 0.350895\n",
      "Validation loss decreased (0.356956 --> 0.350895).  Saving model ...\n",
      "[ 216/1000] train_loss: 0.340337 valid_loss: 0.350235\n",
      "Validation loss decreased (0.350895 --> 0.350235).  Saving model ...\n",
      "[ 217/1000] train_loss: 0.338493 valid_loss: 0.356642\n",
      "EarlyStopping counter: 1 out of 10\n",
      "[ 218/1000] train_loss: 0.335805 valid_loss: 0.346412\n",
      "Validation loss decreased (0.350235 --> 0.346412).  Saving model ...\n",
      "[ 219/1000] train_loss: 0.333998 valid_loss: 0.348995\n",
      "EarlyStopping counter: 1 out of 10\n",
      "[ 220/1000] train_loss: 0.330691 valid_loss: 0.341543\n",
      "Validation loss decreased (0.346412 --> 0.341543).  Saving model ...\n",
      "[ 221/1000] train_loss: 0.328124 valid_loss: 0.336536\n",
      "Validation loss decreased (0.341543 --> 0.336536).  Saving model ...\n",
      "[ 222/1000] train_loss: 0.325834 valid_loss: 0.333796\n",
      "Validation loss decreased (0.336536 --> 0.333796).  Saving model ...\n",
      "[ 223/1000] train_loss: 0.323800 valid_loss: 0.331101\n",
      "Validation loss decreased (0.333796 --> 0.331101).  Saving model ...\n",
      "[ 224/1000] train_loss: 0.321054 valid_loss: 0.333222\n",
      "EarlyStopping counter: 1 out of 10\n",
      "[ 225/1000] train_loss: 0.318725 valid_loss: 0.334234\n",
      "EarlyStopping counter: 2 out of 10\n",
      "[ 226/1000] train_loss: 0.316519 valid_loss: 0.327475\n",
      "Validation loss decreased (0.331101 --> 0.327475).  Saving model ...\n",
      "[ 227/1000] train_loss: 0.313019 valid_loss: 0.328220\n",
      "EarlyStopping counter: 1 out of 10\n",
      "[ 228/1000] train_loss: 0.311337 valid_loss: 0.317760\n",
      "Validation loss decreased (0.327475 --> 0.317760).  Saving model ...\n",
      "[ 229/1000] train_loss: 0.308221 valid_loss: 0.324298\n",
      "EarlyStopping counter: 1 out of 10\n",
      "[ 230/1000] train_loss: 0.307283 valid_loss: 0.316535\n",
      "Validation loss decreased (0.317760 --> 0.316535).  Saving model ...\n",
      "[ 231/1000] train_loss: 0.304537 valid_loss: 0.318690\n",
      "EarlyStopping counter: 1 out of 10\n",
      "[ 232/1000] train_loss: 0.302318 valid_loss: 0.312890\n",
      "Validation loss decreased (0.316535 --> 0.312890).  Saving model ...\n",
      "[ 233/1000] train_loss: 0.299625 valid_loss: 0.315639\n",
      "EarlyStopping counter: 1 out of 10\n",
      "[ 234/1000] train_loss: 0.296942 valid_loss: 0.309207\n",
      "Validation loss decreased (0.312890 --> 0.309207).  Saving model ...\n",
      "[ 235/1000] train_loss: 0.294685 valid_loss: 0.306371\n",
      "Validation loss decreased (0.309207 --> 0.306371).  Saving model ...\n",
      "[ 236/1000] train_loss: 0.293022 valid_loss: 0.303894\n",
      "Validation loss decreased (0.306371 --> 0.303894).  Saving model ...\n",
      "[ 237/1000] train_loss: 0.290392 valid_loss: 0.295713\n",
      "Validation loss decreased (0.303894 --> 0.295713).  Saving model ...\n",
      "[ 238/1000] train_loss: 0.288080 valid_loss: 0.298089\n",
      "EarlyStopping counter: 1 out of 10\n",
      "[ 239/1000] train_loss: 0.286020 valid_loss: 0.296068\n",
      "EarlyStopping counter: 2 out of 10\n",
      "[ 240/1000] train_loss: 0.284110 valid_loss: 0.292010\n",
      "Validation loss decreased (0.295713 --> 0.292010).  Saving model ...\n",
      "[ 241/1000] train_loss: 0.280671 valid_loss: 0.288735\n",
      "Validation loss decreased (0.292010 --> 0.288735).  Saving model ...\n",
      "[ 242/1000] train_loss: 0.278255 valid_loss: 0.292462\n",
      "EarlyStopping counter: 1 out of 10\n",
      "[ 243/1000] train_loss: 0.277086 valid_loss: 0.282425\n",
      "Validation loss decreased (0.288735 --> 0.282425).  Saving model ...\n",
      "[ 244/1000] train_loss: 0.274007 valid_loss: 0.282936\n",
      "EarlyStopping counter: 1 out of 10\n",
      "[ 245/1000] train_loss: 0.272675 valid_loss: 0.277932\n",
      "Validation loss decreased (0.282425 --> 0.277932).  Saving model ...\n",
      "[ 246/1000] train_loss: 0.269458 valid_loss: 0.280781\n",
      "EarlyStopping counter: 1 out of 10\n",
      "[ 247/1000] train_loss: 0.267401 valid_loss: 0.277093\n",
      "Validation loss decreased (0.277932 --> 0.277093).  Saving model ...\n",
      "[ 248/1000] train_loss: 0.264791 valid_loss: 0.274421\n",
      "Validation loss decreased (0.277093 --> 0.274421).  Saving model ...\n",
      "[ 249/1000] train_loss: 0.262278 valid_loss: 0.268911\n",
      "Validation loss decreased (0.274421 --> 0.268911).  Saving model ...\n",
      "[ 250/1000] train_loss: 0.260136 valid_loss: 0.269495\n",
      "EarlyStopping counter: 1 out of 10\n",
      "[ 251/1000] train_loss: 0.257423 valid_loss: 0.269275\n",
      "EarlyStopping counter: 2 out of 10\n",
      "[ 252/1000] train_loss: 0.254633 valid_loss: 0.261705\n",
      "Validation loss decreased (0.268911 --> 0.261705).  Saving model ...\n",
      "[ 253/1000] train_loss: 0.252485 valid_loss: 0.259561\n",
      "Validation loss decreased (0.261705 --> 0.259561).  Saving model ...\n",
      "[ 254/1000] train_loss: 0.249629 valid_loss: 0.257789\n",
      "Validation loss decreased (0.259561 --> 0.257789).  Saving model ...\n",
      "[ 255/1000] train_loss: 0.246804 valid_loss: 0.253466\n",
      "Validation loss decreased (0.257789 --> 0.253466).  Saving model ...\n",
      "[ 256/1000] train_loss: 0.244546 valid_loss: 0.250422\n",
      "Validation loss decreased (0.253466 --> 0.250422).  Saving model ...\n",
      "[ 257/1000] train_loss: 0.242072 valid_loss: 0.248833\n",
      "Validation loss decreased (0.250422 --> 0.248833).  Saving model ...\n",
      "[ 258/1000] train_loss: 0.239880 valid_loss: 0.244457\n",
      "Validation loss decreased (0.248833 --> 0.244457).  Saving model ...\n",
      "[ 259/1000] train_loss: 0.237416 valid_loss: 0.247247\n",
      "EarlyStopping counter: 1 out of 10\n",
      "[ 260/1000] train_loss: 0.234881 valid_loss: 0.242348\n",
      "Validation loss decreased (0.244457 --> 0.242348).  Saving model ...\n",
      "[ 261/1000] train_loss: 0.232956 valid_loss: 0.239631\n",
      "Validation loss decreased (0.242348 --> 0.239631).  Saving model ...\n",
      "[ 262/1000] train_loss: 0.230008 valid_loss: 0.235592\n",
      "Validation loss decreased (0.239631 --> 0.235592).  Saving model ...\n",
      "[ 263/1000] train_loss: 0.227972 valid_loss: 0.237791\n",
      "EarlyStopping counter: 1 out of 10\n",
      "[ 264/1000] train_loss: 0.225512 valid_loss: 0.231506\n",
      "Validation loss decreased (0.235592 --> 0.231506).  Saving model ...\n",
      "[ 265/1000] train_loss: 0.223548 valid_loss: 0.226637\n",
      "Validation loss decreased (0.231506 --> 0.226637).  Saving model ...\n",
      "[ 266/1000] train_loss: 0.221230 valid_loss: 0.229079\n",
      "EarlyStopping counter: 1 out of 10\n",
      "[ 267/1000] train_loss: 0.219182 valid_loss: 0.226977\n",
      "EarlyStopping counter: 2 out of 10\n",
      "[ 268/1000] train_loss: 0.217058 valid_loss: 0.220551\n",
      "Validation loss decreased (0.226637 --> 0.220551).  Saving model ...\n",
      "[ 269/1000] train_loss: 0.215569 valid_loss: 0.220868\n",
      "EarlyStopping counter: 1 out of 10\n",
      "[ 270/1000] train_loss: 0.213786 valid_loss: 0.216583\n",
      "Validation loss decreased (0.220551 --> 0.216583).  Saving model ...\n",
      "[ 271/1000] train_loss: 0.211272 valid_loss: 0.214217\n",
      "Validation loss decreased (0.216583 --> 0.214217).  Saving model ...\n",
      "[ 272/1000] train_loss: 0.210437 valid_loss: 0.216386\n",
      "EarlyStopping counter: 1 out of 10\n",
      "[ 273/1000] train_loss: 0.208310 valid_loss: 0.211950\n",
      "Validation loss decreased (0.214217 --> 0.211950).  Saving model ...\n",
      "[ 274/1000] train_loss: 0.206532 valid_loss: 0.214166\n",
      "EarlyStopping counter: 1 out of 10\n",
      "[ 275/1000] train_loss: 0.206073 valid_loss: 0.218425\n",
      "EarlyStopping counter: 2 out of 10\n",
      "[ 276/1000] train_loss: 0.204257 valid_loss: 0.212647\n",
      "EarlyStopping counter: 3 out of 10\n",
      "[ 277/1000] train_loss: 0.203569 valid_loss: 0.207630\n",
      "Validation loss decreased (0.211950 --> 0.207630).  Saving model ...\n",
      "[ 278/1000] train_loss: 0.201983 valid_loss: 0.207074\n",
      "Validation loss decreased (0.207630 --> 0.207074).  Saving model ...\n",
      "[ 279/1000] train_loss: 0.201238 valid_loss: 0.208688\n",
      "EarlyStopping counter: 1 out of 10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 280/1000] train_loss: 0.200045 valid_loss: 0.209044\n",
      "EarlyStopping counter: 2 out of 10\n",
      "[ 281/1000] train_loss: 0.198617 valid_loss: 0.207420\n",
      "EarlyStopping counter: 3 out of 10\n",
      "[ 282/1000] train_loss: 0.198007 valid_loss: 0.207781\n",
      "EarlyStopping counter: 4 out of 10\n",
      "[ 283/1000] train_loss: 0.196486 valid_loss: 0.208779\n",
      "EarlyStopping counter: 5 out of 10\n",
      "[ 284/1000] train_loss: 0.195372 valid_loss: 0.202259\n",
      "Validation loss decreased (0.207074 --> 0.202259).  Saving model ...\n",
      "[ 285/1000] train_loss: 0.195696 valid_loss: 0.199317\n",
      "Validation loss decreased (0.202259 --> 0.199317).  Saving model ...\n",
      "[ 286/1000] train_loss: 0.194798 valid_loss: 0.201238\n",
      "EarlyStopping counter: 1 out of 10\n",
      "[ 287/1000] train_loss: 0.193018 valid_loss: 0.193458\n",
      "Validation loss decreased (0.199317 --> 0.193458).  Saving model ...\n",
      "[ 288/1000] train_loss: 0.192644 valid_loss: 0.199309\n",
      "EarlyStopping counter: 1 out of 10\n",
      "[ 289/1000] train_loss: 0.192198 valid_loss: 0.194725\n",
      "EarlyStopping counter: 2 out of 10\n",
      "[ 290/1000] train_loss: 0.191101 valid_loss: 0.200834\n",
      "EarlyStopping counter: 3 out of 10\n",
      "[ 291/1000] train_loss: 0.190167 valid_loss: 0.197247\n",
      "EarlyStopping counter: 4 out of 10\n",
      "[ 292/1000] train_loss: 0.189426 valid_loss: 0.196461\n",
      "EarlyStopping counter: 5 out of 10\n",
      "[ 293/1000] train_loss: 0.189414 valid_loss: 0.195810\n",
      "EarlyStopping counter: 6 out of 10\n",
      "[ 294/1000] train_loss: 0.188107 valid_loss: 0.197583\n",
      "EarlyStopping counter: 7 out of 10\n",
      "[ 295/1000] train_loss: 0.187710 valid_loss: 0.190639\n",
      "Validation loss decreased (0.193458 --> 0.190639).  Saving model ...\n",
      "[ 296/1000] train_loss: 0.187046 valid_loss: 0.192998\n",
      "EarlyStopping counter: 1 out of 10\n",
      "[ 297/1000] train_loss: 0.186035 valid_loss: 0.195588\n",
      "EarlyStopping counter: 2 out of 10\n",
      "[ 298/1000] train_loss: 0.185345 valid_loss: 0.195282\n",
      "EarlyStopping counter: 3 out of 10\n",
      "[ 299/1000] train_loss: 0.184867 valid_loss: 0.193108\n",
      "EarlyStopping counter: 4 out of 10\n",
      "[ 300/1000] train_loss: 0.184762 valid_loss: 0.189764\n",
      "Validation loss decreased (0.190639 --> 0.189764).  Saving model ...\n",
      "[ 301/1000] train_loss: 0.183953 valid_loss: 0.192957\n",
      "EarlyStopping counter: 1 out of 10\n",
      "[ 302/1000] train_loss: 0.183030 valid_loss: 0.191182\n",
      "EarlyStopping counter: 2 out of 10\n",
      "[ 303/1000] train_loss: 0.182510 valid_loss: 0.192104\n",
      "EarlyStopping counter: 3 out of 10\n",
      "[ 304/1000] train_loss: 0.182784 valid_loss: 0.187799\n",
      "Validation loss decreased (0.189764 --> 0.187799).  Saving model ...\n",
      "[ 305/1000] train_loss: 0.181783 valid_loss: 0.188576\n",
      "EarlyStopping counter: 1 out of 10\n",
      "[ 306/1000] train_loss: 0.181791 valid_loss: 0.185656\n",
      "Validation loss decreased (0.187799 --> 0.185656).  Saving model ...\n",
      "[ 307/1000] train_loss: 0.181203 valid_loss: 0.189370\n",
      "EarlyStopping counter: 1 out of 10\n",
      "[ 308/1000] train_loss: 0.180180 valid_loss: 0.189030\n",
      "EarlyStopping counter: 2 out of 10\n",
      "[ 309/1000] train_loss: 0.179719 valid_loss: 0.186133\n",
      "EarlyStopping counter: 3 out of 10\n",
      "[ 310/1000] train_loss: 0.179521 valid_loss: 0.184129\n",
      "Validation loss decreased (0.185656 --> 0.184129).  Saving model ...\n",
      "[ 311/1000] train_loss: 0.178031 valid_loss: 0.183805\n",
      "Validation loss decreased (0.184129 --> 0.183805).  Saving model ...\n",
      "[ 312/1000] train_loss: 0.177844 valid_loss: 0.185252\n",
      "EarlyStopping counter: 1 out of 10\n",
      "[ 313/1000] train_loss: 0.177646 valid_loss: 0.181281\n",
      "Validation loss decreased (0.183805 --> 0.181281).  Saving model ...\n",
      "[ 314/1000] train_loss: 0.176996 valid_loss: 0.183713\n",
      "EarlyStopping counter: 1 out of 10\n",
      "[ 315/1000] train_loss: 0.176018 valid_loss: 0.181430\n",
      "EarlyStopping counter: 2 out of 10\n",
      "[ 316/1000] train_loss: 0.176480 valid_loss: 0.187644\n",
      "EarlyStopping counter: 3 out of 10\n",
      "[ 317/1000] train_loss: 0.175668 valid_loss: 0.179613\n",
      "Validation loss decreased (0.181281 --> 0.179613).  Saving model ...\n",
      "[ 318/1000] train_loss: 0.175104 valid_loss: 0.182920\n",
      "EarlyStopping counter: 1 out of 10\n",
      "[ 319/1000] train_loss: 0.174319 valid_loss: 0.182975\n",
      "EarlyStopping counter: 2 out of 10\n",
      "[ 320/1000] train_loss: 0.174284 valid_loss: 0.177482\n",
      "Validation loss decreased (0.179613 --> 0.177482).  Saving model ...\n",
      "[ 321/1000] train_loss: 0.173593 valid_loss: 0.181579\n",
      "EarlyStopping counter: 1 out of 10\n",
      "[ 322/1000] train_loss: 0.172832 valid_loss: 0.177845\n",
      "EarlyStopping counter: 2 out of 10\n",
      "[ 323/1000] train_loss: 0.172772 valid_loss: 0.179704\n",
      "EarlyStopping counter: 3 out of 10\n",
      "[ 324/1000] train_loss: 0.172447 valid_loss: 0.178983\n",
      "EarlyStopping counter: 4 out of 10\n",
      "[ 325/1000] train_loss: 0.171904 valid_loss: 0.178306\n",
      "EarlyStopping counter: 5 out of 10\n",
      "[ 326/1000] train_loss: 0.171212 valid_loss: 0.179146\n",
      "EarlyStopping counter: 6 out of 10\n",
      "[ 327/1000] train_loss: 0.170276 valid_loss: 0.179206\n",
      "EarlyStopping counter: 7 out of 10\n",
      "[ 328/1000] train_loss: 0.169217 valid_loss: 0.180802\n",
      "EarlyStopping counter: 8 out of 10\n",
      "[ 329/1000] train_loss: 0.168965 valid_loss: 0.175783\n",
      "Validation loss decreased (0.177482 --> 0.175783).  Saving model ...\n",
      "[ 330/1000] train_loss: 0.168511 valid_loss: 0.175776\n",
      "Validation loss decreased (0.175783 --> 0.175776).  Saving model ...\n",
      "[ 331/1000] train_loss: 0.167766 valid_loss: 0.175320\n",
      "Validation loss decreased (0.175776 --> 0.175320).  Saving model ...\n",
      "[ 332/1000] train_loss: 0.166771 valid_loss: 0.177065\n",
      "EarlyStopping counter: 1 out of 10\n",
      "[ 333/1000] train_loss: 0.166606 valid_loss: 0.172175\n",
      "Validation loss decreased (0.175320 --> 0.172175).  Saving model ...\n",
      "[ 334/1000] train_loss: 0.165899 valid_loss: 0.175004\n",
      "EarlyStopping counter: 1 out of 10\n",
      "[ 335/1000] train_loss: 0.166339 valid_loss: 0.176613\n",
      "EarlyStopping counter: 2 out of 10\n",
      "[ 336/1000] train_loss: 0.164557 valid_loss: 0.170035\n",
      "Validation loss decreased (0.172175 --> 0.170035).  Saving model ...\n",
      "[ 337/1000] train_loss: 0.163517 valid_loss: 0.173002\n",
      "EarlyStopping counter: 1 out of 10\n",
      "[ 338/1000] train_loss: 0.162595 valid_loss: 0.170351\n",
      "EarlyStopping counter: 2 out of 10\n",
      "[ 339/1000] train_loss: 0.162092 valid_loss: 0.167313\n",
      "Validation loss decreased (0.170035 --> 0.167313).  Saving model ...\n",
      "[ 340/1000] train_loss: 0.161924 valid_loss: 0.167948\n",
      "EarlyStopping counter: 1 out of 10\n",
      "[ 341/1000] train_loss: 0.160422 valid_loss: 0.164852\n",
      "Validation loss decreased (0.167313 --> 0.164852).  Saving model ...\n",
      "[ 342/1000] train_loss: 0.159163 valid_loss: 0.164131\n",
      "Validation loss decreased (0.164852 --> 0.164131).  Saving model ...\n",
      "[ 343/1000] train_loss: 0.158408 valid_loss: 0.163172\n",
      "Validation loss decreased (0.164131 --> 0.163172).  Saving model ...\n",
      "[ 344/1000] train_loss: 0.156854 valid_loss: 0.164044\n",
      "EarlyStopping counter: 1 out of 10\n",
      "[ 345/1000] train_loss: 0.156844 valid_loss: 0.167449\n",
      "EarlyStopping counter: 2 out of 10\n",
      "[ 346/1000] train_loss: 0.155589 valid_loss: 0.159795\n",
      "Validation loss decreased (0.163172 --> 0.159795).  Saving model ...\n",
      "[ 347/1000] train_loss: 0.153784 valid_loss: 0.155566\n",
      "Validation loss decreased (0.159795 --> 0.155566).  Saving model ...\n",
      "[ 348/1000] train_loss: 0.153391 valid_loss: 0.156995\n",
      "EarlyStopping counter: 1 out of 10\n",
      "[ 349/1000] train_loss: 0.152928 valid_loss: 0.156680\n",
      "EarlyStopping counter: 2 out of 10\n",
      "[ 350/1000] train_loss: 0.151033 valid_loss: 0.153448\n",
      "Validation loss decreased (0.155566 --> 0.153448).  Saving model ...\n",
      "[ 351/1000] train_loss: 0.151061 valid_loss: 0.155298\n",
      "EarlyStopping counter: 1 out of 10\n",
      "[ 352/1000] train_loss: 0.150163 valid_loss: 0.153766\n",
      "EarlyStopping counter: 2 out of 10\n",
      "[ 353/1000] train_loss: 0.148918 valid_loss: 0.148922\n",
      "Validation loss decreased (0.153448 --> 0.148922).  Saving model ...\n",
      "[ 354/1000] train_loss: 0.146987 valid_loss: 0.150584\n",
      "EarlyStopping counter: 1 out of 10\n",
      "[ 355/1000] train_loss: 0.147187 valid_loss: 0.151949\n",
      "EarlyStopping counter: 2 out of 10\n",
      "[ 356/1000] train_loss: 0.145807 valid_loss: 0.151945\n",
      "EarlyStopping counter: 3 out of 10\n",
      "[ 357/1000] train_loss: 0.144294 valid_loss: 0.147349\n",
      "Validation loss decreased (0.148922 --> 0.147349).  Saving model ...\n",
      "[ 358/1000] train_loss: 0.144240 valid_loss: 0.146499\n",
      "Validation loss decreased (0.147349 --> 0.146499).  Saving model ...\n",
      "[ 359/1000] train_loss: 0.143295 valid_loss: 0.146878\n",
      "EarlyStopping counter: 1 out of 10\n",
      "[ 360/1000] train_loss: 0.141884 valid_loss: 0.142742\n",
      "Validation loss decreased (0.146499 --> 0.142742).  Saving model ...\n",
      "[ 361/1000] train_loss: 0.141006 valid_loss: 0.142344\n",
      "Validation loss decreased (0.142742 --> 0.142344).  Saving model ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 362/1000] train_loss: 0.140805 valid_loss: 0.141971\n",
      "Validation loss decreased (0.142344 --> 0.141971).  Saving model ...\n",
      "[ 363/1000] train_loss: 0.139371 valid_loss: 0.140896\n",
      "Validation loss decreased (0.141971 --> 0.140896).  Saving model ...\n",
      "[ 364/1000] train_loss: 0.138738 valid_loss: 0.140028\n",
      "Validation loss decreased (0.140896 --> 0.140028).  Saving model ...\n",
      "[ 365/1000] train_loss: 0.139029 valid_loss: 0.142058\n",
      "EarlyStopping counter: 1 out of 10\n",
      "[ 366/1000] train_loss: 0.138167 valid_loss: 0.137021\n",
      "Validation loss decreased (0.140028 --> 0.137021).  Saving model ...\n",
      "[ 367/1000] train_loss: 0.137295 valid_loss: 0.139572\n",
      "EarlyStopping counter: 1 out of 10\n",
      "[ 368/1000] train_loss: 0.136440 valid_loss: 0.134268\n",
      "Validation loss decreased (0.137021 --> 0.134268).  Saving model ...\n",
      "[ 369/1000] train_loss: 0.136377 valid_loss: 0.136456\n",
      "EarlyStopping counter: 1 out of 10\n",
      "[ 370/1000] train_loss: 0.135310 valid_loss: 0.136137\n",
      "EarlyStopping counter: 2 out of 10\n",
      "[ 371/1000] train_loss: 0.134657 valid_loss: 0.136342\n",
      "EarlyStopping counter: 3 out of 10\n",
      "[ 372/1000] train_loss: 0.134523 valid_loss: 0.134055\n",
      "Validation loss decreased (0.134268 --> 0.134055).  Saving model ...\n",
      "[ 373/1000] train_loss: 0.132106 valid_loss: 0.135349\n",
      "EarlyStopping counter: 1 out of 10\n",
      "[ 374/1000] train_loss: 0.132259 valid_loss: 0.136788\n",
      "EarlyStopping counter: 2 out of 10\n",
      "[ 375/1000] train_loss: 0.133580 valid_loss: 0.132653\n",
      "Validation loss decreased (0.134055 --> 0.132653).  Saving model ...\n",
      "[ 376/1000] train_loss: 0.132478 valid_loss: 0.132801\n",
      "EarlyStopping counter: 1 out of 10\n",
      "[ 377/1000] train_loss: 0.132825 valid_loss: 0.133071\n",
      "EarlyStopping counter: 2 out of 10\n",
      "[ 378/1000] train_loss: 0.131003 valid_loss: 0.132166\n",
      "Validation loss decreased (0.132653 --> 0.132166).  Saving model ...\n",
      "[ 379/1000] train_loss: 0.130591 valid_loss: 0.135013\n",
      "EarlyStopping counter: 1 out of 10\n",
      "[ 380/1000] train_loss: 0.130494 valid_loss: 0.134592\n",
      "EarlyStopping counter: 2 out of 10\n",
      "[ 381/1000] train_loss: 0.130976 valid_loss: 0.136448\n",
      "EarlyStopping counter: 3 out of 10\n",
      "[ 382/1000] train_loss: 0.130074 valid_loss: 0.134286\n",
      "EarlyStopping counter: 4 out of 10\n",
      "[ 383/1000] train_loss: 0.130465 valid_loss: 0.130213\n",
      "Validation loss decreased (0.132166 --> 0.130213).  Saving model ...\n",
      "[ 384/1000] train_loss: 0.130007 valid_loss: 0.132091\n",
      "EarlyStopping counter: 1 out of 10\n",
      "[ 385/1000] train_loss: 0.132401 valid_loss: 0.132746\n",
      "EarlyStopping counter: 2 out of 10\n",
      "[ 386/1000] train_loss: 0.130715 valid_loss: 0.130460\n",
      "EarlyStopping counter: 3 out of 10\n",
      "[ 387/1000] train_loss: 0.128743 valid_loss: 0.128421\n",
      "Validation loss decreased (0.130213 --> 0.128421).  Saving model ...\n",
      "[ 388/1000] train_loss: 0.128066 valid_loss: 0.133302\n",
      "EarlyStopping counter: 1 out of 10\n",
      "[ 389/1000] train_loss: 0.128397 valid_loss: 0.130054\n",
      "EarlyStopping counter: 2 out of 10\n",
      "[ 390/1000] train_loss: 0.127569 valid_loss: 0.124883\n",
      "Validation loss decreased (0.128421 --> 0.124883).  Saving model ...\n",
      "[ 391/1000] train_loss: 0.127099 valid_loss: 0.127241\n",
      "EarlyStopping counter: 1 out of 10\n",
      "[ 392/1000] train_loss: 0.126887 valid_loss: 0.130579\n",
      "EarlyStopping counter: 2 out of 10\n",
      "[ 393/1000] train_loss: 0.127084 valid_loss: 0.128497\n",
      "EarlyStopping counter: 3 out of 10\n",
      "[ 394/1000] train_loss: 0.126781 valid_loss: 0.128224\n",
      "EarlyStopping counter: 4 out of 10\n",
      "[ 395/1000] train_loss: 0.126494 valid_loss: 0.130330\n",
      "EarlyStopping counter: 5 out of 10\n",
      "[ 396/1000] train_loss: 0.127157 valid_loss: 0.128707\n",
      "EarlyStopping counter: 6 out of 10\n",
      "[ 397/1000] train_loss: 0.127343 valid_loss: 0.133012\n",
      "EarlyStopping counter: 7 out of 10\n",
      "[ 398/1000] train_loss: 0.126969 valid_loss: 0.125825\n",
      "EarlyStopping counter: 8 out of 10\n",
      "[ 399/1000] train_loss: 0.126277 valid_loss: 0.127926\n",
      "EarlyStopping counter: 9 out of 10\n",
      "[ 400/1000] train_loss: 0.125416 valid_loss: 0.130807\n",
      "EarlyStopping counter: 10 out of 10\n",
      "-----------> Early stopping: no improvement after 10 consecutive epochs\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Fitting OAE\n",
    "projection = DimensionalityReductionOAE(initial_train_set=training_set)\n",
    "seed = 42\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "projection.fit(encoding_layers=[16, 160, 80, 40, 20, 10], penalty_term=0.1, nr_epochs=1000, patience=10, \n",
    "               batch=1000, verbose=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
